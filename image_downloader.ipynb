{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_downloader.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hl1R1IM-2eYS",
        "outputId": "0e550cf1-41e2-4816-9471-35f6df037ca1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PNcf_xu2n6J"
      },
      "source": [
        "import pickle\n",
        "from keras.models import load_model\n",
        "\n",
        "# Read photo ids\n",
        "keyword_photoid_urls = pickle.load(open('/content/gdrive/My Drive/images/keyword_photoid_urls.pkl', 'rb'))\n",
        "\n",
        "# Load classification model\n",
        "model = load_model('/content/gdrive/My Drive/images/classification_model_religion.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJcM_g9T3cgg"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def resize_image(image, resolutions, uniform_background=True):\n",
        "    \"\"\"\n",
        "    Resize an image to the wanted resolution.\n",
        "    Same factor is applied along x and y axis\n",
        "    \"\"\"\n",
        "\n",
        "    h, w, _ = image.shape\n",
        "\n",
        "    # Transform into a square image\n",
        "    if h>w:\n",
        "        nb_before, nb_after = int((h-w)/2), h - w - int((h-w)/2)\n",
        "        before, after = np.zeros((h, nb_before, 3)) + 255, np.zeros((h, nb_after, 3)) + 255\n",
        "        image_t = np.concatenate((before, image, after), axis=1).astype(np.uint8)\n",
        "    elif h<w:\n",
        "        nb_before, nb_after = int((w-h)/2), w - h - int((w-h)/2)\n",
        "        before, after = np.zeros((nb_before, w, 3)) + 255, np.zeros((nb_after, w, 3)) + 255\n",
        "        image_t = np.concatenate((before, image, after), axis=0).astype(np.uint8)\n",
        "    elif h==w:\n",
        "        image_t = image\n",
        "\n",
        "    # Resize image\n",
        "    resized_images = []\n",
        "    for resolution in resolutions:\n",
        "        image_resized = cv2.resize(image_t, (resolution, resolution))\n",
        "\n",
        "        # Set uniform white background (255, 255, 255)\n",
        "        # It Background may be black or white, we set white everywhere to be consistent\n",
        "        if uniform_background:\n",
        "            border = (image_resized==255).all(axis=2) | (image_resized==0).all(axis=2)\n",
        "            border_rgb = np.repeat(np.expand_dims(border, -1), 3, axis=2)\n",
        "            image_resized[border_rgb] = 255\n",
        "\n",
        "        resized_images.append(image_resized)\n",
        "\n",
        "    return resized_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWGaebEP4YcZ"
      },
      "source": [
        "import urllib\n",
        "\n",
        "def download_image(photo_id_urls, photo_id, path):\n",
        "\n",
        "    if not photo_id in photo_id_urls:\n",
        "        print(f'{photo_id} not in dict.')\n",
        "        return False\n",
        "        \n",
        "    urls = photo_id_urls[photo_id]\n",
        "    if len(urls)>0:\n",
        "        # Select the size with lower resolution but higher than 1E6 pixels\n",
        "        sizes = sorted([(int(i[0]), int(i[1])) for i in urls.keys() if i!=('','')], key=lambda i: i[0] * i[1])\n",
        "        sizes = [s for s in sizes if s[0]*s[1]<1E7]\n",
        "        sizes_t = [s for s in sizes if s[0]*s[1]>=1E6]\n",
        "        if len(sizes_t)==0:\n",
        "            size = sizes[-1]\n",
        "        else:\n",
        "            size = sizes_t[0]\n",
        "\n",
        "        try:\n",
        "            urllib.request.urlretrieve(urls[(str(size[0]), str(size[1]))], path)\n",
        "            return True\n",
        "        except:\n",
        "            print('Download error', photo_id)\n",
        "\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RPZH1C23PJ5",
        "outputId": "1cd704a1-8354-4996-9247-0b97213361b4"
      },
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "root = 'data'\n",
        "os.makedirs(root, exist_ok=True)\n",
        "\n",
        "keyword = 'protestant_temple'\n",
        "\n",
        "photoid_urls = keyword_photoid_urls[keyword]\n",
        "tot = 10000\n",
        "n = 0\n",
        "photoids = sorted(photoid_urls.keys())[tot * n : tot * (n+1)]\n",
        "photoid_preds = {}\n",
        "batch_nb, batch_photoids, batch_images = 0, [], []\n",
        "for e, photo_id in enumerate(tqdm(photoids)):\n",
        "\n",
        "    if e%1000==0:\n",
        "        print(e)\n",
        "\n",
        "    # Build image paths\n",
        "    f_path = f'{e:06d}_{photo_id}.jpg'\n",
        "    path = f'{root}/{f_path}'\n",
        "    res = download_image(photoid_urls, photo_id, path)\n",
        "\n",
        "    if res:\n",
        "        img = cv2.imread(path)\n",
        "        if img is not None:\n",
        "            # Resize\n",
        "            img_256 = resize_image(img, [256], uniform_background=False)[0]\n",
        "            batch_nb += 1\n",
        "            batch_photoids.append(path)\n",
        "            batch_images.append(img_256)\n",
        "\n",
        "    if batch_nb==16:\n",
        "        # Prediction\n",
        "        predictions = model.predict(np.array(batch_images) / 255.).reshape(-1)\n",
        "\n",
        "        # Set predictions\n",
        "        for id_, pred in zip(batch_photoids, predictions):\n",
        "          photoid_preds[id_] = pred\n",
        "\n",
        "        batch_nb, batch_photoids, batch_images = 0, [], []\n",
        "\n",
        "pickle.dump(photoid_preds, open(f'/content/gdrive/My Drive/images/photoid_preds_{keyword}_{n}.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4601 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 1000/4601 [13:43<1:04:30,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 1307/4601 [17:58<34:52,  1.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Download error 26609162543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|███       | 1399/4601 [19:15<33:10,  1.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Download error 27214737715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 2000/4601 [27:51<37:32,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 2717/4601 [37:51<21:41,  1.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Download error 42551630165\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 3000/4601 [41:43<17:05,  1.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 4000/4601 [54:59<07:17,  1.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4601/4601 [1:02:42<00:00,  1.22it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhioidAT6EJT",
        "outputId": "a74ad4cc-3f14-4d10-d388-ea761e42fb65"
      },
      "source": [
        "print(len(photoid_preds))\n",
        "#download_image(photoid_urls, photo_id, path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCvkyi7i6UnT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}